# AI Agent Configuration

Source: mod/ai v0.1.0 | Generated: 2026-01-29

> **DO NOT EDIT** — This file is auto-generated by `sync.sh`.
> Edit `.ai-context.md` for project-specific context.

---

# shooter.nvim -- Project Context

## Project Overview

Neovim plugin for managing iterative development workflows using a shot-based approach. Shots are discrete work units defined in markdown shotfiles, which can be sent to AI agents via tmux panes. Refactored from divramod's dotfiles next-action workflow into a standalone, publishable plugin.

## Tech Stack

- **Language**: Lua (Neovim plugin)
- **Test Framework**: plenary.nvim (busted-style)
- **Dependencies**: telescope.nvim, oil.nvim, nui.nvim
- **External**: tmux, Claude Code CLI

## Repository Structure

```
lua/shooter/           Plugin source code
  core/                Core modules (files, shots, movement, project, context)
  telescope/           Telescope pickers and actions
  tmux/                Tmux integration (send, detect, create, panes)
  queue/               Shot queue management
  dashboard/           NuiTree dashboard UI
  session/             YAML session management
  keymaps/             Context-specific keymaps (picker, oil)
  context/             Context detection and resolvers
templates/             Context file templates
tests/                 plenary.nvim test specs
doc/                   Vim help documentation
plans/prompts/         Shotfiles (development tasks)
.shooter.nvim/         Per-repo config and images
```

## Development Workflow

- Work tracked in beads (`bd`), prefix: `snvim`
- Shots in `plans/prompts/*.md` define features and fixes
- `bd ready` to find work, `bd close` to complete
- Tests run via plenary: `:PlenaryBustedDirectory tests/`

## Key Conventions

- **200-line maximum per file**: Enforces single responsibility
- **Zero auto-initialization**: Plugin only activates when `setup()` is called
- **Context-aware commands**: Same keymap works identically across telescope, oil, and buffer contexts
- **8 namespaces**: Shotfile, Shot, Tmux, Subproject, Tools, Cfg, Analytics, Help

## Important Notes

- Always update README.md when adding commands, keybindings, or config options
- All modules have corresponding `*_spec.lua` test files
- Context files: global at `~/.config/shooter.nvim/`, project at `.shooter.nvim/`

---

# Coding Standards

Universal coding standards for all languages and projects.

## Clarity

- Write clean, readable code; prefer clarity over cleverness
- Functions should do one thing and be short enough to understand at a glance
- Use meaningful, descriptive names for variables, functions, and files
- Code should read like prose — a new developer should follow the logic without comments

## Structure

- One concept per function; one responsibility per module
- Keep nesting shallow (max 2-3 levels); extract early returns or helper functions
- Order code top-down: public API first, helpers below
- Group related logic together; separate unrelated concerns

## Naming

- Variables: describe what it holds (`userCount`, not `n`)
- Functions: describe what it does (`fetchUserProfile`, not `getData`)
- Booleans: use `is`/`has`/`should` prefixes (`isActive`, `hasPermission`)
- Files: match the primary export or concept they contain

## Constants and Magic Values

- No magic numbers or strings — use named constants
- Group related constants in enums or constant objects
- Configuration values belong in config files, not scattered in code

## DRY and Abstraction

- DRY applies at 3+ repetitions; don't abstract after the first duplication
- Three similar lines of code beats a premature abstraction
- Prefer composition over inheritance
- Extract when you have a clear, stable interface — not before

## Error Handling

- Validate at system boundaries (API inputs, file reads, user data)
- Trust internal code — don't defensively check everything
- Fail fast with clear error messages
- Handle errors at the level that can do something useful about them
- Never swallow errors silently

## Code Hygiene

- No commented-out code — git history preserves everything
- No dead code; delete unused functions and imports
- Avoid premature optimization — measure first, optimize second
- TODO comments must include a beads issue ID or be removed
- Keep files under 300 lines; split when they grow beyond that

## Dependencies

- Prefer standard library over third-party when the gap is small
- Evaluate dependencies for maintenance status and bundle size
- Pin dependency versions for reproducible builds
- One package manager per project — no mixing npm/yarn/pnpm

---

# Security Rules

Security practices required across all projects and languages. These rules align with the [OWASP Top 10 2021](https://owasp.org/Top10/) security risks.

## Secrets Management

- Never commit secrets, keys, tokens, or passwords to version control
- Use environment variables or secret managers for sensitive configuration
- Add secret patterns to `.gitignore` and use git pre-commit hooks to catch leaks
- Rotate any credential that was ever exposed, even briefly
- Use `.env.example` with placeholder values, never real secrets

## Input Validation

*Addresses A03:2021 Injection*

- Validate all user input at system boundaries
- Never trust client-side validation alone — always validate server-side
- Use allowlists over denylists for input validation
- Reject unexpected input; don't try to sanitize it into validity
- Validate types, ranges, lengths, and formats

## Output Security

*Addresses A03:2021 Injection*

- Sanitize all output to prevent XSS (cross-site scripting)
- Use context-aware encoding (HTML, URL, JavaScript, CSS)
- Set `Content-Security-Policy` headers
- Escape user-generated content before rendering

## Database Security

*Addresses A03:2021 Injection*

- Use parameterized queries — never concatenate SQL strings
- Apply principle of least privilege to database accounts
- Never expose raw database errors to users
- Sanitize and validate all query parameters

## Authentication and Authorization

*Addresses A01:2021 Broken Access Control, A07:2021 Identification and Authentication Failures*

- Follow principle of least privilege for all access
- Use established auth libraries — never roll your own crypto
- Hash passwords with bcrypt/argon2 — never SHA/MD5
- Implement rate limiting on auth endpoints
- Use short-lived tokens; implement refresh token rotation

## Dependency Security

*Addresses A06:2021 Vulnerable and Outdated Components*

- Keep dependencies updated; automate vulnerability scanning
- Audit new dependencies before adding them
- Use lockfiles for reproducible builds
- Pin versions in production

## Code Safety

*Addresses A03:2021 Injection, A08:2021 Software and Data Integrity Failures*

- No `eval()` or dynamic code execution from user input
- No deserialization of untrusted data
- Avoid shell command injection — use library APIs instead of exec
- Disable debug mode and verbose errors in production

## Infrastructure

*Addresses A05:2021 Security Misconfiguration, A09:2021 Security Logging and Monitoring Failures*

- HTTPS everywhere — no exceptions
- Set secure cookie flags: `HttpOnly`, `Secure`, `SameSite`
- Implement CORS with specific origins, not wildcards
- Log security events; never log sensitive data

---

# Commit Conventions

Git commit standards for all repositories.

## Format

```
type(scope): description [beads-id]

Optional body explaining WHY, not WHAT.

BD-Actor: <agent-name>
Co-Authored-By: <name> <email>
```

## Subject Line

- Use conventional commits: `type(scope): description`
- Keep under 72 characters
- Use imperative mood: "add feature" not "added feature"
- Reference beads issue ID in brackets: `[ai-xyz.1]`
- Lowercase after the colon

## Types

| Type       | When to use                        |
|------------|------------------------------------|
| `feat`     | New feature or capability          |
| `fix`      | Bug fix                            |
| `refactor` | Code change that doesn't fix/add   |
| `docs`     | Documentation only                 |
| `chore`    | Maintenance, deps, config          |
| `test`     | Adding or updating tests           |
| `ci`       | CI/CD pipeline changes             |
| `perf`     | Performance improvement            |
| `style`    | Formatting, whitespace, lint fixes |

## Scope

- Use the module, package, or feature area: `feat(auth): add login`
- Use the beads prefix for cross-cutting: `chore(beads): sync state`
- Omit scope only for truly global changes

## Body

- Separate from subject with a blank line
- Explain WHY the change was made, not WHAT changed (the diff shows that)
- Wrap at 72 characters
- Reference related issues or context

## Trailers

- **BD-Actor** (required for AI commits): identifies the agent persona
  - See `multi-agent-conventions.md` for actor definitions
- **Co-Authored-By** (required for AI commits): `Co-Authored-By: Claude <noreply@anthropic.com>`
- Place trailers after the body, separated by a blank line

## Rules

- One logical change per commit — don't mix refactoring with features
- Never commit broken code to main
- Squash fixup commits before merge
- Rebase feature branches; merge to main

---

# Multi-Agent Conventions

Rules for coordinating work across AI coding agents. All agents operating in repos that use the ai ruleset MUST follow these conventions.

---

## 1. BD_ACTOR Naming

Every agent session MUST set `BD_ACTOR` before interacting with beads. This identifies who performed each action in the audit trail.

| Agent | BD_ACTOR |
|-------|----------|
| Claude Code (Opus 4.5) | `claude-opus` |
| Claude Code (Sonnet 4) | `claude-sonnet` |
| OpenCode (GPT-5.2 Codex) | `opencode-gpt52` |
| OpenCode (Gemini 3 Pro) | `opencode-gemini3` |
| OpenCode (GLM-4.7) | `opencode-glm47` |
| OpenCode (DeepSeek Reasoner) | `opencode-deepseek` |
| OpenCode (Qwen3-Coder) | `opencode-qwen3` |
| OpenCode (Grok Code Fast) | `opencode-grok` |
| OpenCode (Kimi K2.5) | `opencode-kimi` |
| Gemini CLI | `gemini-cli` |
| Codex CLI | `codex-cli` |
| Kimi CLI | `kimi-cli` |
| Human | `mod` |

Set it at session start:
```bash
export BD_ACTOR=claude-opus
```

---

## 2. Commit Convention

Every commit MUST include the beads issue ID in the subject line and a `BD-Actor` trailer. AI-authored commits also include a `Co-Authored-By` trailer.

Format:
```
<type>(<scope>): <description> [<beads-id>]

BD-Actor: <bd-actor>
Co-Authored-By: <Agent Name> <noreply@provider.com>
```

Example:
```
feat(rules): add typescript standards [ai-a3f8]

BD-Actor: claude-opus
Co-Authored-By: Claude Opus 4.5 <noreply@anthropic.com>
```

Rules:
- `<type>` follows conventional commits: feat, fix, refactor, docs, chore, test, ci, perf, style
- `<scope>` is the area of the codebase affected
- `[<beads-id>]` is the short beads issue hash (e.g. `ai-a3f8`). Omit only for trivial housekeeping with no tracked issue.
- `BD-Actor` is the agent's BD_ACTOR value from the table above
- `Co-Authored-By` is required for all AI-generated commits

---

## 3. Session Handoff Protocol

### Ending a session

1. Close completed issues: `bd close <id> --reason "description of what was accomplished"`
2. Comment on in-progress work: `bd comments add <id> "status update with what remains"`
3. Sync beads to git: `bd sync`
4. Push: `git push`

### Starting a session

1. Set BD_ACTOR: `export BD_ACTOR=<your-actor>`
2. Pull latest: `git pull`
3. Context loads automatically via `bd prime` (Claude/Gemini hooks) or AGENTS.md instructions (OpenCode/Codex)
4. Check actionable tasks: `bd ready --json`
5. Pick a task and claim it: `bd update <id> --status in_progress`

### Responding to `bd ready`

When the user runs `bd ready` (or asks what to work on next), the agent MUST show at least 10 ready issues, prioritized by what makes the most sense to work on next. Consider priority level, dependency order, and logical sequencing (e.g. foundational work before dependent work). Always present the list — never silently pick a task without showing options.

---

## 4. Beads Progress Tracking

AI agents MUST write progress into beads at every meaningful checkpoint. Beads is the single source of truth for what happened -- not progress.txt, not plan files, not ad-hoc notes.

### When working on a beads issue:

1. **Claim it**: `bd update <id> --status in_progress`
2. **Comment on progress**: After each significant step, record what was done and the result:
   ```
   bd comments add <id> "Completed: <what>. Result: <outcome>"
   ```
3. **Close with summary**: `bd close <id> --reason "<what was accomplished>"`

### What to include in comments:

- What was done (files changed, features added, bugs fixed)
- The result (tests pass, build succeeds, issue resolved)
- Blockers encountered and how they were resolved
- Decisions made and why

---

## 5. Context Rot Prevention

These rules prevent stale context and duplicated sources of truth across multi-agent workflows.

1. **Single source of truth**: Beads owns progress. Plan files own design. Never duplicate progress in both. Do NOT update plan files when completing tasks.
2. **No orphan work**: Every significant work item gets a beads issue. Use `bd create` immediately when you discover something that needs doing, even mid-session.
3. **File findings immediately**: When you discover bugs, inconsistencies, or improvements during reviews, audits, or any work — create a beads issue for each finding you do not fix on the spot. Never leave findings only in conversation context or summary text; they must be persisted as beads issues to survive session boundaries.
4. **Comment-as-you-go**: Write beads comments after each meaningful step (see section 4). Do not batch updates to the end of a session.
5. **Session handoff protocol**: Always follow the ending/starting procedures in section 3. No silent session exits.
6. **Plan file is a blueprint**: After implementation starts, plan files are only updated for design changes (new phases, changed approach). Never update them for progress tracking.

---

## 6. Consistency Across Repos

All repositories under `~/a/` MUST use identical tooling configuration. Consistency is key for workflows that span multiple repos.

1. **Beads sync mode**: All repos use **direct mode** (no `sync-branch`). JSONL lives on the `main` branch so `bv` and all tools read from the same source. Never set `sync-branch` in `.beads/config.yaml`. If a repo has `sync-branch` set, clear it: `bd config set sync.branch ""`, remove the skip-worktree flag: `git update-index --no-skip-worktree .beads/issues.jsonl`, then `bd sync` and commit the JSONL.
2. **Beads initialization**: Every linked repo gets `bd init` + `bd hooks install` + `bd setup claude`. Use the prefix from `projects.json`.
3. **Git ignore patterns**: Every repo ignores `.ai-rules/` and beads runtime files (`.beads/beads.db*`, `.beads/.local_version`, `.bv/`). The `.beads/issues.jsonl`, `.beads/config.yaml`, `.beads/metadata.json`, and `.beads/interactions.jsonl` are committed.
4. **Context file wiring**: Every repo has `.ai-context.md` referenced at the top of `CLAUDE.md` (`@.ai-context.md`) and `GEMINI.md` (`@./.ai-context.md`).

---

## 7. Shot Workflow

See `rules/core/shot-workflow.md` for full rules.

Key points: shotfiles are **read-only input**. Create a beads issue per shot, track execution there, never write back to the shotfile.

---

## 8. Artifact Persistence

See `rules/core/artifact-persistence.md` for full rules.

Key points: all AI output of lasting value must be persisted to the filesystem. Research goes to `plans/research/`, plans to `plans/<cli-name>/`. Different CLIs write to separate subdirectories to avoid conflicts.

---

# Shot Workflow Rules

Rules for processing shots (task instructions) from plan files.

## Core Principle

Shotfiles are **read-only input**. Never modify the source shot file.

## Workflow

1. **Receive** a shot from `plans/prompts/` or a plan file
2. **Create** a beads issue for the work described in the shot
3. **Set** the beads issue to `in-progress`
4. **Execute** the work described in the shot
5. **Comment** results and relevant output on the beads issue
6. **Close** the beads issue when work is complete

## Rules

- **NEVER write back to the shotfile** — it is immutable input
- Create exactly one beads issue per shot (unless the shot specifies sub-tasks)
- The beads issue is the record of execution — put all status and output there
- If a shot requires multiple steps, track progress via beads comments
- If a shot is blocked, comment the blocker on the beads issue and leave it open
- Reference the shot source in the beads issue description for traceability

## Shot Sources

- `plans/prompts/*.md` — standalone shot files
- Inline shots within plan documents
- Shots may reference other shots; follow the dependency chain

## Output

- All work products go to their designated locations (see `artifact-persistence.md`)
- The beads issue captures what was done, decisions made, and any follow-up needed
- Never leave work untracked — if you did it, the beads issue should reflect it

---

## Commands

### /review.md

# /review

Code review command. Analyze code for bugs, security issues, performance, and maintainability.

## Usage

```bash
/review path/to/file.ts          # Review a single file
/review --pr 42                  # Review a pull request
/review --diff                   # Review staged changes
/review --dir src/auth/          # Review all files in a directory
```

## Steps

### 1. Determine Input and Gather Context

- **File path**: Read the file directly
- **PR number**: Fetch with `gh pr diff <number>`
- **`--diff`**: Run `git diff --staged` (fall back to `git diff`)
- **Directory**: Collect all source files recursively
- If no argument, review current staged changes
- Read imports and existing tests to understand module context

### 2. Review Systematically

| Category | What to Check |
|----------|---------------|
| **Bugs** | Null access, off-by-one, race conditions, unhandled promises |
| **Security** | OWASP Top 10: injection, broken auth, XSS, CSRF, sensitive data exposure |
| **Performance** | N+1 queries, unnecessary re-renders, memory leaks, unbounded loops |
| **Readability** | Unclear naming, deep nesting, missing types, magic numbers |
| **Maintainability** | Duplication, tight coupling, missing error handling |

### 3. Categorize Findings

- **Critical**: Security vulnerability, data loss, or crash. Must fix before merge.
- **Warning**: Bug or correctness concern. Should fix before merge.
- **Suggestion**: Style or refactoring opportunity. Consider for future.

### 4. Format Output

```markdown
## Code Review: [target]

### Summary
[1-2 sentence overview]

### Findings
#### Critical
- **[file:line]** [description] -- Fix: [remediation]

#### Warnings
- **[file:line]** [description] -- Fix: [remediation]

#### Suggestions
- **[file:line]** [description] -- Consider: [improvement]

### What Looks Good
[1-2 things done well]
```

### 5. Provide Actionable Fixes

For each finding, give a concrete fix (code snippet or description), not just the problem. For security issues, reference the relevant OWASP category. Prioritize by impact: security > correctness > performance > style.

## Tips

- Focus on substantive issues, not style nitpicks handled by linters
- If reviewing a PR, check the description for intent context
- When uncertain, note it as a question rather than a finding

### /refactor.md

# /refactor

Refactoring command. Improve code structure without changing behavior.

## Usage

```bash
/refactor path/to/file.ts                # Refactor an entire file
/refactor path/to/file.ts:42-80          # Refactor specific line range
/refactor path/to/file.ts functionName   # Refactor a specific function
```

## Steps

### 1. Read and Understand the Code

- Read the target file or code block in full
- Read existing tests that cover this code
- Note the project's code style from neighboring files

### 2. Identify Code Smells

| Smell | Indicator |
|-------|-----------|
| Long method | Function exceeds 30-40 lines |
| God class/module | File handles too many responsibilities |
| Deep nesting | More than 3 levels of indentation |
| Duplicate code | Similar logic repeated in multiple places |
| Feature envy | Function uses another module's data more than its own |
| Long parameter list | More than 3-4 parameters |
| Dead code | Unused functions, unreachable branches |
| Magic numbers | Hardcoded values without named constants |

### 3. Plan the Refactoring

For each smell, propose a technique: extract function, extract variable, inline, rename, move, introduce parameter object, guard clause, replace conditional with polymorphism.

### 4. Verify Tests Exist

- If tests exist, run them to confirm they pass before changing anything
- If no tests cover the code, write characterization tests first
- Never refactor untested code without adding tests

### 5. Apply Incrementally

1. Apply one refactoring at a time
2. Run tests after each change
3. If a test fails, revert and investigate
4. Preserve all public interfaces and external behavior

### 6. Run Full Verification

Run the project's full test/lint suite. All checks must pass.

### 7. Present Before/After

```markdown
## Refactoring Complete: [target]

### Changes
1. [Refactoring applied] -- [why it improves the code]

### Before / After
[Relevant code snippets showing the transformation]

### Verification
- Tests: pass | Lint: pass | Types: pass
```

## Rules

- No functional changes -- code must behave identically after refactoring
- Follow existing project style and patterns
- Small steps, each independently verifiable
- Never skip test verification between changes

### /test.md

# /test

Test generation command. Create comprehensive unit tests for a file or function.

## Usage

```bash
/test path/to/file.ts              # Generate tests for an entire file
/test path/to/file.ts myFunction   # Generate tests for a specific function
/test --coverage path/to/module/   # Improve coverage for a directory
```

## Steps

### 1. Analyze the Target Code

- Read the target file or function completely
- Identify all public functions, methods, and exported interfaces
- Map out code paths: branches, loops, early returns, error throws
- List external dependencies that need mocking

### 2. Detect the Testing Framework

| Config | Framework |
|--------|-----------|
| `vitest.config.*` | Vitest |
| `jest.config.*` or package.json jest key | Jest |
| `pytest.ini` / `pyproject.toml` pytest section | Pytest |
| `Cargo.toml` dev-dependencies | Rust `#[test]` |
| `*_test.go` convention | Go `testing` |

Also detect assertion libraries and mocking tools from existing test files.

### 3. Locate or Create the Test File

Follow the project's existing convention (co-located `file.test.ts`, `__tests__/`, or mirror structure). If a test file exists, read it to avoid duplicating coverage.

### 4. Design Test Cases

For each function, cover:

- **Happy path**: Expected inputs produce expected outputs
- **Edge cases**: Empty inputs, boundary values, single-element collections, special characters
- **Error cases**: Invalid inputs, network failures, timeout scenarios

### 5. Write Tests Using AAA Pattern

Every test follows Arrange, Act, Assert:

```
describe("[ModuleName]", () => {
  describe("[functionName]", () => {
    it("should [expected behavior] when [condition]", () => {
      // Arrange - set up data and dependencies
      // Act - call the function under test
      // Assert - verify the result
    });
  });
});
```

### 6. Mock External Dependencies

- Mock network calls, database, file system
- Use the project's preferred mocking approach
- Never mock the code under test itself
- Keep mocks minimal

### 7. Run and Verify

Execute tests using the project's deterministic command (`pnpm run test`, `make test`, `pytest`, `cargo test`, `go test ./...`). All new tests must pass.

## Rules

- Match existing test style and conventions
- Deterministic: no timing, random values, or external state dependencies
- Descriptive names: test names should read as behavior documentation
- Independent: each test runs in isolation
- Test behavior, not implementation details

### /debug.md

# /debug

Debug command. Systematically analyze errors and propose fixes.

## Usage

```bash
/debug "TypeError: Cannot read properties of undefined"   # Debug from error message
/debug --trace                                             # Debug from stack trace
/debug path/to/file.ts:42                                  # Debug a specific location
/debug --issue "login fails after session expires"         # Debug from description
```

## Steps

### 1. Capture Error Context

- **Error message**: Parse error type, message, file/line references
- **Stack trace**: Extract call chain, identify originating file and line
- **File + line**: Read 20 lines above and below the location
- **Bug description**: Identify expected vs actual behavior

### 2. Reproduce the Problem

- What function or endpoint is involved?
- What input or state triggers the issue?
- Is it deterministic or intermittent?
- Check recent changes: `git log --oneline -10 -- <file>`

### 3. Read Relevant Code

Work outward from the error location:
1. The function where the error occurs
2. The caller (one level up the stack)
3. Type definitions and interfaces involved
4. Config files if the error relates to environment

### 4. Identify Root Cause

| Symptom | Likely Cause |
|---------|-------------|
| `undefined`/`null` access | Missing null check, async timing, wrong data shape |
| Type error | Wrong argument type, schema mismatch |
| Network error | Wrong URL, missing auth, CORS, timeout |
| Test failure | Changed behavior, missing mock, stale snapshot |
| Build failure | Missing import, circular dependency, version mismatch |

### 5. Propose and Apply Fix

```markdown
## Debug Report

### Error
[error message or bug description]

### Root Cause
[clear explanation of why]

### Fix
[code change with explanation]
```

Apply the fix, run targeted tests, then run the full suite to check for regressions.

### 6. Track Non-Trivial Fixes

If the fix touches multiple files or changes behavior:
- Create a beads issue: `bd create --title="Fix: [description]" --type=bug`
- Document the root cause and approach in the issue

### 7. Prevent Recurrence

Consider: should a test be added? Could this occur elsewhere? Should a lint rule or type constraint prevent this class of bug? Recommend preventive measures.

## Tips

- Start from the error and work backward through the call chain
- Use `git log` and `git blame` to see when behavior changed
- For intermittent bugs, look for race conditions or caching
- If stuck after 30 minutes, create a beads issue and document findings so far

---

## Beads Workflow

All work is tracked in beads (`bd`), not markdown files.

```bash
bd ready              # Find available work
bd show <id>          # View issue details
bd update <id> --status in_progress  # Claim work
bd close <id>         # Complete work
bd sync               # Sync with git remote
```

### Session Close Protocol

Before ending any session:

```bash
git status              # Check what changed
git add <files>         # Stage code changes
bd sync                 # Commit beads changes
git commit -m "..."     # Commit code
bd sync                 # Commit any new beads changes
git push                # Push to remote
```
